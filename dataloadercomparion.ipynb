{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataloadercomparion",
      "provenance": [],
      "authorship_tag": "ABX9TyPHpsJ8bx1315P0MXpu/i8l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachelombok/exploreCSR-scan2CAD/blob/master/dataloadercomparion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdjaqkHeACqZ",
        "outputId": "1ce54759-c21d-498e-9813-3bd135580e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20220414.tar.gz (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 30 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 40 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting iopath\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore) (1.21.5)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 10.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore) (4.64.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20220414-py3-none-any.whl size=61211 sha256=e26cd37071057dff272d1778820f2f0977dcb47287ec31c8ac2e3ffd1775f8b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/f4/b8/7b5df8b6722f4c72315ce70c31aa693e00cef6a5056149bd28\n",
            "Successfully built fvcore\n",
            "Installing collected packages: pyyaml, portalocker, yacs, iopath, fvcore\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed fvcore-0.1.5.post20220414 iopath-0.1.9 portalocker-2.4.0 pyyaml-6.0 yacs-0.1.8\n",
            "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py37_cu111_pyt1100/download.html\n",
            "Collecting pytorch3d\n",
            "  Downloading https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py37_cu111_pyt1100/pytorch3d-0.6.1-cp37-cp37m-linux_x86_64.whl (44.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 44.7 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: iopath in /usr/local/lib/python3.7/dist-packages (from pytorch3d) (0.1.9)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.7/dist-packages (from pytorch3d) (0.1.5.post20220414)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d) (4.64.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d) (1.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d) (6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d) (1.21.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d) (0.8.9)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d) (7.1.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d) (0.1.8)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath->pytorch3d) (2.4.0)\n",
            "Installing collected packages: pytorch3d\n",
            "Successfully installed pytorch3d-0.6.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"1.10.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip3 install fvcore iopath\n",
        "        !pip3 install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip3 install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from pytorch3d.io import load_obj, save_obj\n",
        "from pytorch3d.structures import Meshes\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch3d.utils import ico_sphere\n",
        "from pytorch3d.ops import sample_points_from_meshes\n",
        "from pytorch3d.loss import (\n",
        "    chamfer_distance, \n",
        "    mesh_edge_loss, \n",
        "    mesh_laplacian_smoothing, \n",
        "    mesh_normal_consistency,\n",
        ")\n",
        "from pytorch3d.renderer import (\n",
        "    look_at_view_transform,\n",
        "    FoVPerspectiveCameras, \n",
        "    FoVOrthographicCameras, \n",
        "    Materials, \n",
        "    RasterizationSettings, \n",
        "    MeshRenderer, \n",
        "    MeshRasterizer,  \n",
        "    SoftPhongShader,\n",
        "    TexturesVertex,\n",
        "    TexturesAtlas,\n",
        "    PointsRenderer,\n",
        "    PointsRasterizationSettings,\n",
        "    PointsRasterizer\n",
        ")\n",
        "from pytorch3d.datasets import (\n",
        "    R2N2,\n",
        "    ShapeNetCore,\n",
        "    collate_batched_meshes,\n",
        "    render_cubified_voxels,\n",
        ")\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "%matplotlib notebook \n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import sys\n",
        "mpl.rcParams['savefig.dpi'] = 80\n",
        "mpl.rcParams['figure.dpi'] = 80\n",
        "sys.path.append(os.path.abspath(''))\n",
        "# Set the device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"WARNING: CPU only, this will be slow!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEYebxupA_b4",
        "outputId": "eb957d6f-d9f1-4ada-c35e-3f275e2ff054"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: CPU only, this will be slow!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/pytorch3d/data/dolphin/dolphin.obj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTlXfIJNBheH",
        "outputId": "477167b5-f735-4729-8ee6-c5eaa1abb1fc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-19 13:01:08--  https://dl.fbaipublicfiles.com/pytorch3d/data/dolphin/dolphin.obj\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.162.83, 108.157.162.120, 108.157.162.108, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.162.83|:443... connected.\n",
            "OpenSSL: error:1408F10B:SSL routines:ssl3_get_record:wrong version number\n",
            "Unable to establish SSL connection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dolphin mesh.\n",
        "trg_obj = os.path.join('dolphin.obj')"
      ],
      "metadata": {
        "id": "8PlPdv1zDGe8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We read the target 3D model using load_obj\n",
        "verts, faces, aux = load_obj(trg_obj)\n",
        "\n",
        "# verts is a FloatTensor of shape (V, 3) where V is the number of vertices in the mesh\n",
        "# faces is an object which contains the following LongTensors: verts_idx, normals_idx and textures_idx\n",
        "# For this tutorial, normals and textures are ignored.\n",
        "faces_idx = faces.verts_idx.to(device)\n",
        "verts = verts.to(device)\n",
        "\n",
        "# We scale normalize and center the target mesh to fit in a sphere of radius 1 centered at (0,0,0). \n",
        "# (scale, center) will be used to bring the predicted mesh to its original center and scale\n",
        "# Note that normalizing the target mesh, speeds up the optimization but is not necessary!\n",
        "center = verts.mean(0)\n",
        "verts = verts - center\n",
        "scale = max(verts.abs().max(0)[0])\n",
        "verts = verts / scale\n",
        "\n",
        "# We construct a Meshes structure for the target mesh\n",
        "trg_mesh = Meshes(verts=[verts], faces=[faces_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "MEGbLXhK6_Hp",
        "outputId": "6e46b07f-a5ee-4c83-bd68-43e206327cd0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d641a72af6e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We read the target 3D model using load_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# verts is a FloatTensor of shape (V, 3) where V is the number of vertices in the mesh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# faces is an object which contains the following LongTensors: verts_idx, normals_idx and textures_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch3d/io/obj_io.py\u001b[0m in \u001b[0;36mload_obj\u001b[0;34m(f, load_textures, create_texture_atlas, texture_atlas_size, texture_wrap, device, path_manager)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpath_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mpath_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPathManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         return _load_obj(\n\u001b[1;32m    222\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch3d/io/utils.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(f, path_manager, mode)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPathManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mContextManager\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/iopath/common/file_io.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, buffering, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \"\"\"\n\u001b[1;32m   1011\u001b[0m         \u001b[0mhandler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_path_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         \u001b[0mbret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0mkvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_open_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/iopath/common/file_io.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, path, mode, buffering, encoding, errors, newline, closefd, opener, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0mclosefd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosefd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0mopener\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         )\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dolphin.obj'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('We have {0} vertices and {1} faces.'.format(verts.shape[0], faces.verts_idx.shape[0]))"
      ],
      "metadata": {
        "id": "oqn7d-837DfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataloader for shapenet"
      ],
      "metadata": {
        "id": "Eh-AwqgK7f-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Y1SF4Pc_7gEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    torch.cuda.set_device(device)\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    \n",
        "SHAPENET_PATH = \"\" #shapenetcore dataset folder path\n",
        "shapenet_dataset = ShapeNetCore(SHAPENET_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "PosF9Qog7HKw",
        "outputId": "ec81f4da-9f04-42c0-ebb1-c2f7c3b54a17"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6becd41a0edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mSHAPENET_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mshapenet_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShapeNetCore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSHAPENET_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch3d/datasets/shapenet/shapenet_core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_dir, synsets, version, load_textures, texture_resolution)\u001b[0m\n\u001b[1;32m     96\u001b[0m             synset_set = {\n\u001b[1;32m     97\u001b[0m                 \u001b[0msynset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0msynset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0msynset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynset_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "R2N2_PATH = \"\" #r2n2 dataset path\n",
        "SPLITS_PATH = \"None\"\n",
        "r2n2_dataset = R2N2(\"train\", SHAPENET_PATH, R2N2_PATH, SPLITS_PATH, return_voxels=True)"
      ],
      "metadata": {
        "id": "NDJNRF7O7zRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shapenet_model = shapenet_dataset[6]\n",
        "print(\"This model belongs to the category \" + shapenet_model[\"synset_id\"] + \".\")\n",
        "print(\"This model has model id \" + shapenet_model[\"model_id\"] + \".\")\n",
        "model_verts, model_faces = shapenet_model[\"verts\"], shapenet_model[\"faces\"]"
      ],
      "metadata": {
        "id": "DJf2C1lr71pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_textures = TexturesVertex(verts_features=torch.ones_like(model_verts, device=device)[None])\n",
        "shapenet_model_mesh = Meshes(\n",
        "    verts=[model_verts.to(device)],   \n",
        "    faces=[model_faces.to(device)],\n",
        "    textures=model_textures\n",
        ")"
      ],
      "metadata": {
        "id": "Rg3Et6HF75X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "point clodu comparison work"
      ],
      "metadata": {
        "id": "FOw6Rd4i8PDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pointcloud(mesh, title=\"\"):\n",
        "    # Sample points uniformly from the surface of the mesh.\n",
        "    points = sample_points_from_meshes(mesh, 5000)\n",
        "    x, y, z = points.clone().detach().cpu().squeeze().unbind(1)    \n",
        "    fig = plt.figure(figsize=(5, 5))\n",
        "    ax = Axes3D(fig)\n",
        "    ax.scatter3D(x, z, -y)\n",
        "    ax.set_xlabel('x')\n",
        "    ax.set_ylabel('z')\n",
        "    ax.set_zlabel('y')\n",
        "    ax.set_title(title)\n",
        "    ax.view_init(190, 30)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "s-gv0_0j8QwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pointcloud(trg_mesh, \"Target mesh\")\n",
        "plot_pointcloud(shapenet_model_mesh, \"ShapeNet mesh\")"
      ],
      "metadata": {
        "id": "ixViPPUf8RxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "optimization loop loss"
      ],
      "metadata": {
        "id": "gJ0bQZ5U9S6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will learn to deform the source mesh by offsetting its vertices\n",
        "# The shape of the deform parameters is equal to the total number of vertices in src_mesh\n",
        "deform_verts = torch.full(shapenet_model_mesh.verts_packed().shape, 0.0, device=device, requires_grad=True)"
      ],
      "metadata": {
        "id": "hONa2n-a9WZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The optimizer\n",
        "optimizer = torch.optim.SGD([deform_verts], lr=1.0, momentum=0.9)"
      ],
      "metadata": {
        "id": "r-Gtduhi9aMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of optimization steps\n",
        "Niter = 2000\n",
        "# Weight for the chamfer loss\n",
        "w_chamfer = 1.0 \n",
        "# Weight for mesh edge loss\n",
        "w_edge = 1.0 \n",
        "# Weight for mesh normal consistency\n",
        "w_normal = 0.01 \n",
        "# Weight for mesh laplacian smoothing\n",
        "w_laplacian = 0.1 \n",
        "# Plot period for the losses\n",
        "plot_period = 250\n",
        "loop = tqdm(range(Niter))\n",
        "\n",
        "chamfer_losses = []\n",
        "laplacian_losses = []\n",
        "edge_losses = []\n",
        "normal_losses = []\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "for i in loop:\n",
        "    # Initialize optimizer\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Deform the mesh\n",
        "    new_src_mesh = shapenet_model_mesh.offset_verts(deform_verts)\n",
        "    \n",
        "    # We sample 5k points from the surface of each mesh \n",
        "    sample_trg = sample_points_from_meshes(trg_mesh, 5000)\n",
        "    sample_src = sample_points_from_meshes(new_src_mesh, 5000)\n",
        "    \n",
        "    # We compare the two sets of pointclouds by computing (a) the chamfer loss\n",
        "    loss_chamfer, _ = chamfer_distance(sample_trg, sample_src)\n",
        "    \n",
        "    # and (b) the edge length of the predicted mesh\n",
        "    loss_edge = mesh_edge_loss(new_src_mesh)\n",
        "    \n",
        "    # mesh normal consistency\n",
        "    loss_normal = mesh_normal_consistency(new_src_mesh)\n",
        "    \n",
        "    # mesh laplacian smoothing\n",
        "    loss_laplacian = mesh_laplacian_smoothing(new_src_mesh, method=\"uniform\")\n",
        "    \n",
        "    # Weighted sum of the losses\n",
        "    loss = loss_chamfer * w_chamfer + loss_edge * w_edge + loss_normal * w_normal + loss_laplacian * w_laplacian\n",
        "    \n",
        "    # Print the losses\n",
        "    loop.set_description('total_loss = %.6f' % loss)\n",
        "    \n",
        "    # Save the losses for plotting\n",
        "    chamfer_losses.append(float(loss_chamfer.detach().cpu()))\n",
        "    edge_losses.append(float(loss_edge.detach().cpu()))\n",
        "    normal_losses.append(float(loss_normal.detach().cpu()))\n",
        "    laplacian_losses.append(float(loss_laplacian.detach().cpu()))\n",
        "    \n",
        "    # Plot mesh\n",
        "    if i % plot_period == 0:\n",
        "        plot_pointcloud(new_src_mesh, title=\"iter: %d\" % i)\n",
        "        \n",
        "    # Optimization step\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "pWq3EPOV9eue"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}